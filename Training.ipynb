{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SimonGeb/Deep-Learning/blob/main/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otg__TfbTiic"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dGuiyjNT9pt"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/TU Delft/Master/Deep Learning/Reproducability Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejIhtmB3Udi0"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade tf_slim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swEG_s1gUeAW"
      },
      "outputs": [],
      "source": [
        "pip install rawpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bg3COytmUPJL"
      },
      "outputs": [],
      "source": [
        "# uniform content loss + adaptive threshold + per_class_input + recursive G\n",
        "# improvement upon cqf37\n",
        "from __future__ import division\n",
        "import os, time, scipy.io\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import tf_slim as slim\n",
        "import numpy as np\n",
        "import rawpy\n",
        "import glob\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syn5U_UjUjXV"
      },
      "outputs": [],
      "source": [
        "# set directories here\n",
        "input_dir = './dataset/Sony/short/'\n",
        "gt_dir = './dataset/Sony/long/'\n",
        "checkpoint_dir = './checkpoint/Own_RMSprop/'\n",
        "result_dir = './result_Own_RMSprop/'\n",
        "\n",
        "# get train IDs\n",
        "train_fns = glob.glob(gt_dir + '0*.ARW')\n",
        "train_ids = [int(os.path.basename(train_fn)[0:5]) for train_fn in train_fns]\n",
        "print(train_ids)\n",
        "print(len(train_ids))\n",
        "ps = 512  # patch size for training\n",
        "save_freq = 500\n",
        "num_epochs = 4000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZMCKs-R9hIa"
      },
      "outputs": [],
      "source": [
        "#set different debug schemes\n",
        "DEBUG = None \n",
        "if DEBUG == 1:\n",
        "    save_freq = 2\n",
        "    train_ids = train_ids[0:5]\n",
        "    num_epochs = 10\n",
        "if DEBUG == 2:\n",
        "    save_freq = 5\n",
        "    train_ids = train_ids[0:40]\n",
        "    num_epochs = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGWBPgFAU9zu"
      },
      "outputs": [],
      "source": [
        "def lrelu(x):\n",
        "    return tf.maximum(x * 0.2, x)\n",
        "\n",
        "def bytescale(data, cmin=None, cmax=None, high=255, low=0):\n",
        "    \"\"\"\n",
        "    Byte scales an array (image).\n",
        "    Byte scaling means converting the input image to uint8 dtype and scaling\n",
        "    the range to ``(low, high)`` (default 0-255).\n",
        "    If the input image already has dtype uint8, no scaling is done.\n",
        "    This function is only available if Python Imaging Library (PIL) is installed.\n",
        "    \"\"\"\n",
        "    if data.dtype == np.uint8:\n",
        "        return data\n",
        "\n",
        "    if high > 255:\n",
        "        raise ValueError(\"`high` should be less than or equal to 255.\")\n",
        "    if low < 0:\n",
        "        raise ValueError(\"`low` should be greater than or equal to 0.\")\n",
        "    if high < low:\n",
        "        raise ValueError(\"`high` should be greater than or equal to `low`.\")\n",
        "\n",
        "    if cmin is None:\n",
        "        cmin = data.min()\n",
        "    if cmax is None:\n",
        "        cmax = data.max()\n",
        "\n",
        "    cscale = cmax - cmin\n",
        "    if cscale < 0:\n",
        "        raise ValueError(\"`cmax` should be larger than `cmin`.\")\n",
        "    elif cscale == 0:\n",
        "        cscale = 1\n",
        "\n",
        "    scale = float(high - low) / cscale\n",
        "    bytedata = (data - cmin) * scale + low\n",
        "    return (bytedata.clip(low, high) + 0.5).astype(np.uint8)\n",
        "\n",
        "\n",
        "def toimage(arr, high=255, low=0, cmin=None, cmax=None, pal=None,\n",
        "            mode=None, channel_axis=None):\n",
        "    \"\"\"Takes a numpy array and returns a PIL image.\n",
        "    \"\"\"\n",
        "    data = np.asarray(arr)\n",
        "    if np.iscomplexobj(data):\n",
        "        raise ValueError(\"Cannot convert a complex-valued array.\")\n",
        "    shape = list(data.shape)\n",
        "    valid = len(shape) == 2 or ((len(shape) == 3) and\n",
        "                                ((3 in shape) or (4 in shape)))\n",
        "    if not valid:\n",
        "        raise ValueError(\"'arr' does not have a suitable array shape for \"\n",
        "                         \"any mode.\")\n",
        "    if len(shape) == 2:\n",
        "        shape = (shape[1], shape[0])  # columns show up first\n",
        "        if mode == 'F':\n",
        "            data32 = data.astype(np.float32)\n",
        "            image = Image.frombytes(mode, shape, data32.tostring())\n",
        "            return image\n",
        "        if mode in [None, 'L', 'P']:\n",
        "            bytedata = bytescale(data, high=high, low=low,\n",
        "                                 cmin=cmin, cmax=cmax)\n",
        "            image = Image.frombytes('L', shape, bytedata.tostring())\n",
        "            if pal is not None:\n",
        "                image.putpalette(np.asarray(pal, dtype=np.uint8).tostring())\n",
        "                # Becomes a mode='P' automagically.\n",
        "            elif mode == 'P':  # default gray-scale\n",
        "                pal = (np.arange(0, 256, 1, dtype=np.uint8)[:, np.newaxis] *\n",
        "                       np.ones((3,), dtype=np.uint8)[np.newaxis, :])\n",
        "                image.putpalette(np.asarray(pal, dtype=np.uint8).tostring())\n",
        "            return image\n",
        "        if mode == '1':  # high input gives threshold for 1\n",
        "            bytedata = (data > high)\n",
        "            image = Image.frombytes('1', shape, bytedata.tostring())\n",
        "            return image\n",
        "        if cmin is None:\n",
        "            cmin = np.amin(np.ravel(data))\n",
        "        if cmax is None:\n",
        "            cmax = np.amax(np.ravel(data))\n",
        "        data = (data*1.0 - cmin)*(high - low)/(cmax - cmin) + low\n",
        "        if mode == 'I':\n",
        "            data32 = data.astype(np.uint32)\n",
        "            image = Image.frombytes(mode, shape, data32.tostring())\n",
        "        else:\n",
        "            raise ValueError(_errstr)\n",
        "        return image\n",
        "\n",
        "    # if here then 3-d array with a 3 or a 4 in the shape length.\n",
        "    # Check for 3 in datacube shape --- 'RGB' or 'YCbCr'\n",
        "    if channel_axis is None:\n",
        "        if (3 in shape):\n",
        "            ca = np.flatnonzero(np.asarray(shape) == 3)[0]\n",
        "        else:\n",
        "            ca = np.flatnonzero(np.asarray(shape) == 4)\n",
        "            if len(ca):\n",
        "                ca = ca[0]\n",
        "            else:\n",
        "                raise ValueError(\"Could not find channel dimension.\")\n",
        "    else:\n",
        "        ca = channel_axis\n",
        "\n",
        "    numch = shape[ca]\n",
        "    if numch not in [3, 4]:\n",
        "        raise ValueError(\"Channel axis dimension is not valid.\")\n",
        "\n",
        "    bytedata = bytescale(data, high=high, low=low, cmin=cmin, cmax=cmax)\n",
        "    if ca == 2:\n",
        "        strdata = bytedata.tostring()\n",
        "        shape = (shape[1], shape[0])\n",
        "    elif ca == 1:\n",
        "        strdata = np.transpose(bytedata, (0, 2, 1)).tostring()\n",
        "        shape = (shape[2], shape[0])\n",
        "    elif ca == 0:\n",
        "        strdata = np.transpose(bytedata, (1, 2, 0)).tostring()\n",
        "        shape = (shape[2], shape[1])\n",
        "    if mode is None:\n",
        "        if numch == 3:\n",
        "            mode = 'RGB'\n",
        "        else:\n",
        "            mode = 'RGBA'\n",
        "\n",
        "    if mode not in ['RGB', 'RGBA', 'YCbCr', 'CMYK']:\n",
        "        raise ValueError(_errstr)\n",
        "\n",
        "    if mode in ['RGB', 'YCbCr']:\n",
        "        if numch != 3:\n",
        "            raise ValueError(\"Invalid array shape for mode.\")\n",
        "    if mode in ['RGBA', 'CMYK']:\n",
        "        if numch != 4:\n",
        "            raise ValueError(\"Invalid array shape for mode.\")\n",
        "\n",
        "    # Here we know data and mode is correct\n",
        "    image = Image.frombytes(mode, shape, strdata)\n",
        "    return image\n",
        "\n",
        "def upsample_and_concat(x1, x2, output_channels, in_channels):\n",
        "    pool_size = 2\n",
        "    deconv_filter = tf.Variable(tf.truncated_normal([pool_size, pool_size, output_channels, in_channels], stddev=0.02))\n",
        "    deconv = tf.nn.conv2d_transpose(x1, deconv_filter, tf.shape(x2), strides=[1, pool_size, pool_size, 1])\n",
        "\n",
        "    deconv_output = tf.concat([deconv, x2], 3)\n",
        "    deconv_output.set_shape([None, None, None, output_channels * 2])\n",
        "\n",
        "    return deconv_output\n",
        "\n",
        "\n",
        "def network(input):\n",
        "    conv1 = slim.conv2d(input, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_1')\n",
        "    conv1 = slim.conv2d(conv1, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_2')\n",
        "    pool1 = slim.max_pool2d(conv1, [2, 2], padding='SAME')\n",
        "\n",
        "    conv2 = slim.conv2d(pool1, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv2_1')\n",
        "    conv2 = slim.conv2d(conv2, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv2_2')\n",
        "    pool2 = slim.max_pool2d(conv2, [2, 2], padding='SAME')\n",
        "\n",
        "    conv3 = slim.conv2d(pool2, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv3_1')\n",
        "    conv3 = slim.conv2d(conv3, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv3_2')\n",
        "    pool3 = slim.max_pool2d(conv3, [2, 2], padding='SAME')\n",
        "\n",
        "    conv4 = slim.conv2d(pool3, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv4_1')\n",
        "    conv4 = slim.conv2d(conv4, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv4_2')\n",
        "    pool4 = slim.max_pool2d(conv4, [2, 2], padding='SAME')\n",
        "\n",
        "    conv5 = slim.conv2d(pool4, 512, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv5_1')\n",
        "    conv5 = slim.conv2d(conv5, 512, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv5_2')\n",
        "\n",
        "    up6 = upsample_and_concat(conv5, conv4, 256, 512)\n",
        "    conv6 = slim.conv2d(up6, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv6_1')\n",
        "    conv6 = slim.conv2d(conv6, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv6_2')\n",
        "\n",
        "    up7 = upsample_and_concat(conv6, conv3, 128, 256)\n",
        "    conv7 = slim.conv2d(up7, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv7_1')\n",
        "    conv7 = slim.conv2d(conv7, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv7_2')\n",
        "\n",
        "    up8 = upsample_and_concat(conv7, conv2, 64, 128)\n",
        "    conv8 = slim.conv2d(up8, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv8_1')\n",
        "    conv8 = slim.conv2d(conv8, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv8_2')\n",
        "\n",
        "    up9 = upsample_and_concat(conv8, conv1, 32, 64)\n",
        "    conv9 = slim.conv2d(up9, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv9_1')\n",
        "    conv9 = slim.conv2d(conv9, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv9_2')\n",
        "\n",
        "    conv10 = slim.conv2d(conv9, 12, [1, 1], rate=1, activation_fn=None, scope='g_conv10')\n",
        "    out = tf.depth_to_space(conv10, 2)\n",
        "    return out\n",
        "\n",
        "\n",
        "def pack_raw(raw):\n",
        "    # pack Bayer image to 4 channels\n",
        "    im = raw.raw_image_visible.astype(np.float32)\n",
        "    black = raw.black_level_per_channel\n",
        "    im = np.maximum((im - np.mean(black)), 0) / ((16383) - np.mean(black))  # subtract the black level\n",
        "  \n",
        "    im = np.expand_dims(im, axis=2)\n",
        "    img_shape = im.shape\n",
        "  \n",
        "    H = img_shape[0]\n",
        "    W = img_shape[1]\n",
        "    if (raw.raw_pattern == ([[1, 0], [2, 3]])).all():\n",
        "      G = im[0:H:2, 0:W:2, :] # Every alternating value starting from position (0,0) \n",
        "      R = im[0:H:2, 1:W:2, :] # Every alternating value starting from position (0,1) \n",
        "      G_e = im[1:H:2, 1:W:2, :] # Every alternating value starting from position (1,1) \n",
        "      B = im[1:H:2, 0:W:2, :] # Every alternating value starting from position (1,0)\n",
        "    if (raw.raw_pattern == ([[0, 1], [3, 2]])).all():\n",
        "      R = im[0:H:2, 0:W:2, :] # Every alternating value starting from position (0,0) \n",
        "      G = im[0:H:2, 1:W:2, :] # Every alternating value starting from position (0,1) \n",
        "      B = im[1:H:2, 1:W:2, :] # Every alternating value starting from position (1,1) \n",
        "      G_e = im[1:H:2, 0:W:2, :] # Every alternating value starting from position (1,0)  \n",
        "    if (raw.raw_pattern == ([[1, 2], [0, 3]])).all():\n",
        "      G = im[0:H:2, 0:W:2, :] # Every alternating value starting from position (0,0) \n",
        "      B = im[0:H:2, 1:W:2, :] # Every alternating value starting from position (0,1) \n",
        "      G_e = im[1:H:2, 1:W:2, :] # Every alternating value starting from position (1,1) \n",
        "      R = im[1:H:2, 0:W:2, :] # Every alternating value starting from position (1,0)\n",
        "    if (raw.raw_pattern == ([[2, 1], [3, 0]])).all():\n",
        "      B = im[0:H:2, 0:W:2, :] # Every alternating value starting from position (0,0) \n",
        "      G = im[0:H:2, 1:W:2, :] # Every alternating value starting from position (0,1) \n",
        "      R = im[1:H:2, 1:W:2, :] # Every alternating value starting from position (1,1) \n",
        "      G_e = im[1:H:2, 0:W:2, :] # Every alternating value starting from position (1,0)\n",
        "    out = np.concatenate((R, G, B, G_e), axis=2) # Always in R-G-B-G format\n",
        "    \n",
        "    return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIet0qLUZNOI"
      },
      "outputs": [],
      "source": [
        "sess = tf.Session()\n",
        "in_image = tf.placeholder(tf.float32, [None, None, None, 4])\n",
        "gt_image = tf.placeholder(tf.float32, [None, None, None, 3])\n",
        "out_image = network(in_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABWciBIgVWx5"
      },
      "outputs": [],
      "source": [
        "G_loss = tf.reduce_mean(tf.abs(out_image - gt_image))\n",
        "\n",
        "t_vars = tf.trainable_variables()\n",
        "lr = tf.placeholder(tf.float32)\n",
        "# set different optimizer here\n",
        "#G_opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(G_loss)\n",
        "#G_opt = tf.compat.v1.train.AdadeltaOptimizer(learning_rate=1.0).minimize(G_loss)\n",
        "G_opt = tf.compat.v1.train.RMSPropOptimizer(learning_rate=1e-4).minimize(G_loss)\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
        "if ckpt:\n",
        "    print('loaded ' + ckpt.model_checkpoint_path)\n",
        "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "\n",
        "# Raw data takes long time to load. Keep them in memory after loaded.\n",
        "gt_images = [None] * 6000\n",
        "input_images = {}\n",
        "input_images['300'] = [None] * len(train_ids)\n",
        "input_images['250'] = [None] * len(train_ids)\n",
        "input_images['100'] = [None] * len(train_ids)\n",
        "\n",
        "g_loss = np.zeros((5000, 1))\n",
        "\n",
        "allfolders = glob.glob(result_dir + '*0')\n",
        "lastepoch = 0\n",
        "for folder in allfolders:\n",
        "    lastepoch = np.maximum(lastepoch, int(folder[-4:]))\n",
        "\n",
        "losses = []\n",
        "times = []\n",
        "\n",
        "print('Debug scheme: ', DEBUG, 'Nr. images: ', len(train_ids))\n",
        "\n",
        "learning_rate = 1e-4\n",
        "for epoch in range(lastepoch, num_epochs+1):\n",
        "    if os.path.isdir(result_dir + '%04d' % epoch):\n",
        "        continue\n",
        "    cnt = 0\n",
        "    if epoch > 2000:\n",
        "        learning_rate = 1e-5\n",
        "\n",
        "    for ind in np.random.permutation(len(train_ids)):\n",
        "        # get the path from image id\n",
        "        train_id = train_ids[ind]\n",
        "        print(train_id)\n",
        "        in_files = glob.glob(input_dir + '%05d_00*.ARW' % train_id)\n",
        "        in_path = in_files[np.random.random_integers(0, len(in_files) - 1)]\n",
        "        in_fn = os.path.basename(in_path)\n",
        "\n",
        "        gt_files = glob.glob(gt_dir + '%05d_00*.ARW' % train_id)\n",
        "        gt_path = gt_files[0]\n",
        "        gt_fn = os.path.basename(gt_path)\n",
        "        in_exposure = float(in_fn[9:-5])\n",
        "        gt_exposure = float(gt_fn[9:-5])\n",
        "        ratio = min(gt_exposure / in_exposure, 300)\n",
        "\n",
        "        st = time.time()\n",
        "        cnt += 1\n",
        "\n",
        "        if input_images[str(ratio)[0:3]][ind] is None:\n",
        "            raw = rawpy.imread(in_path)\n",
        "            input_images[str(ratio)[0:3]][ind] = np.expand_dims(pack_raw(raw), axis=0) * ratio\n",
        "\n",
        "            gt_raw = rawpy.imread(gt_path)\n",
        "            im = gt_raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
        "            gt_images[ind] = np.expand_dims(np.float32(im / 65535.0), axis=0)\n",
        "\n",
        "        # crop\n",
        "        H = input_images[str(ratio)[0:3]][ind].shape[1]\n",
        "        W = input_images[str(ratio)[0:3]][ind].shape[2]\n",
        "\n",
        "        xx = np.random.randint(0, W - ps)\n",
        "        yy = np.random.randint(0, H - ps)\n",
        "        input_patch = input_images[str(ratio)[0:3]][ind][:, yy:yy + ps, xx:xx + ps, :]\n",
        "        gt_patch = gt_images[ind][:, yy * 2:yy * 2 + ps * 2, xx * 2:xx * 2 + ps * 2, :]\n",
        "\n",
        "        if np.random.randint(2, size=1)[0] == 1:  # random flip\n",
        "            input_patch = np.flip(input_patch, axis=1)\n",
        "            gt_patch = np.flip(gt_patch, axis=1)\n",
        "        if np.random.randint(2, size=1)[0] == 1:\n",
        "            input_patch = np.flip(input_patch, axis=2)\n",
        "            gt_patch = np.flip(gt_patch, axis=2)\n",
        "        if np.random.randint(2, size=1)[0] == 1:  # random transpose\n",
        "            input_patch = np.transpose(input_patch, (0, 2, 1, 3))\n",
        "            gt_patch = np.transpose(gt_patch, (0, 2, 1, 3))\n",
        "\n",
        "        input_patch = np.minimum(input_patch, 1.0)\n",
        "\n",
        "        _, G_current, output = sess.run([G_opt, G_loss, out_image],\n",
        "                                        feed_dict={in_image: input_patch, gt_image: gt_patch, lr: learning_rate})\n",
        "        output = np.minimum(np.maximum(output, 0), 1)\n",
        "        g_loss[ind] = G_current\n",
        "\n",
        "        print(\"%d %d Loss=%.3f Time=%.3f\" % (epoch, cnt, np.mean(g_loss[np.where(g_loss)]), time.time() - st))\n",
        "        losses.append(np.mean(g_loss[np.where(g_loss)]))\n",
        "        times.append(time.time() - st)\n",
        "        if epoch % save_freq == 0:\n",
        "            if not os.path.isdir(result_dir + '%04d' % epoch):\n",
        "                os.makedirs(result_dir + '%04d' % epoch)\n",
        "\n",
        "            temp = np.concatenate((gt_patch[0, :, :, :], output[0, :, :, :]), axis=1)\n",
        "            toimage(temp * 255, high=255, low=0, cmin=0, cmax=255).save(\n",
        "                result_dir + '%04d/%05d_00_train_%d.jpg' % (epoch, train_id, ratio))\n",
        "\n",
        "    saver.save(sess, checkpoint_dir + 'model.ckpt')\n",
        "    np.save(checkpoint_dir + \"losses\", losses)\n",
        "    np.save(checkpoint_dir + \"times\", times)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlOvlyO3F378"
      },
      "outputs": [],
      "source": [
        "# save the model\n",
        "saver.save(sess, checkpoint_dir + 'model.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zY0ysN8J6x2"
      },
      "outputs": [],
      "source": [
        "# save the losses\n",
        "np.save(checkpoint_dir + \"losses\", losses)\n",
        "np.save(checkpoint_dir + \"times\", times)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqC5rLQYmBE-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}