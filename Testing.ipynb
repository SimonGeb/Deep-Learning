{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SimonGeb/Deep-Learning/blob/main/Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otg__TfbTiic",
        "outputId": "a90cbeb8-5713-4424-cf31-dba78f257ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dGuiyjNT9pt",
        "outputId": "3fe4f33b-7822-47a1-8240-481ac0b70189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1DuKt88mVXJTHanb5KcuJgrsmJcTSkPkb/Reproducability Project\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/TU Delft/Master/Deep Learning/Reproducability Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejIhtmB3Udi0",
        "outputId": "333e7197-8a04-4396-8fb8-3dfaf8e91ca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.9/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from tf_slim) (1.4.0)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade tf_slim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swEG_s1gUeAW",
        "outputId": "d4faf67d-9b12-4a47-8e34-f88c80f461b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rawpy\n",
            "  Downloading rawpy-0.18.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rawpy) (1.22.4)\n",
            "Installing collected packages: rawpy\n",
            "Successfully installed rawpy-0.18.0\n"
          ]
        }
      ],
      "source": [
        "pip install rawpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg3COytmUPJL",
        "outputId": "b5b44be0-7e06-40b7-985f-5ed8b58a14ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "# uniform content loss + adaptive threshold + per_class_input + recursive G\n",
        "# improvement upon cqf37\n",
        "from __future__ import division\n",
        "import os, scipy.io\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import tf_slim as slim\n",
        "import numpy as np\n",
        "import rawpy\n",
        "import glob\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syn5U_UjUjXV",
        "outputId": "5801d073-bfe6-41b3-8fca-3fb880e0f24b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10003, 10004, 10005]\n"
          ]
        }
      ],
      "source": [
        "# change input and output directories here\n",
        "input_dir = './dataset/Own_iPhone/Short/'\n",
        "gt_dir = './dataset/Own_iPhone/Long/'\n",
        "result_dir = './result_Own_Adam_full/'\n",
        "\n",
        "# change loaded model here\n",
        "checkpoint_dir = './checkpoint/Own_Adam_full/'\n",
        "\n",
        "\n",
        "# get test IDs. Based on the image format, the extention might be different\n",
        "# test_fns = glob.glob(gt_dir + '/1*.ARW') # for Sony images\n",
        "test_fns = glob.glob(gt_dir + '/1*.dng') # for smartphone images\n",
        "test_ids = [int(os.path.basename(test_fn)[0:5]) for test_fn in test_fns]\n",
        "print(test_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGWBPgFAU9zu"
      },
      "outputs": [],
      "source": [
        "\n",
        "DEBUG = 1\n",
        "if DEBUG == 1:\n",
        "    save_freq = 1\n",
        "    test_ids = test_ids[0:5]\n",
        "\n",
        "\n",
        "def lrelu(x):\n",
        "    return tf.maximum(x * 0.2, x)\n",
        "\n",
        "# this function is not available in rawpy anymore so is imported manually\n",
        "def bytescale(data, cmin=None, cmax=None, high=255, low=0):\n",
        "    \"\"\"\n",
        "    Byte scales an array (image).\n",
        "    Byte scaling means converting the input image to uint8 dtype and scaling\n",
        "    the range to ``(low, high)`` (default 0-255).\n",
        "    If the input image already has dtype uint8, no scaling is done.\n",
        "    This function is only available if Python Imaging Library (PIL) is installed.\n",
        "    \"\"\"\n",
        "    if data.dtype == np.uint8:\n",
        "        return data\n",
        "\n",
        "    if high > 255:\n",
        "        raise ValueError(\"`high` should be less than or equal to 255.\")\n",
        "    if low < 0:\n",
        "        raise ValueError(\"`low` should be greater than or equal to 0.\")\n",
        "    if high < low:\n",
        "        raise ValueError(\"`high` should be greater than or equal to `low`.\")\n",
        "\n",
        "    if cmin is None:\n",
        "        cmin = data.min()\n",
        "    if cmax is None:\n",
        "        cmax = data.max()\n",
        "\n",
        "    cscale = cmax - cmin\n",
        "    if cscale < 0:\n",
        "        raise ValueError(\"`cmax` should be larger than `cmin`.\")\n",
        "    elif cscale == 0:\n",
        "        cscale = 1\n",
        "\n",
        "    scale = float(high - low) / cscale\n",
        "    bytedata = (data - cmin) * scale + low\n",
        "    return (bytedata.clip(low, high) + 0.5).astype(np.uint8)\n",
        "\n",
        "# this function is not available in rawpy anymore so is imported manually\n",
        "def toimage(arr, high=255, low=0, cmin=None, cmax=None, pal=None,\n",
        "            mode=None, channel_axis=None):\n",
        "    \"\"\"Takes a numpy array and returns a PIL image.\n",
        "    This function is only available if Python Imaging Library (PIL) is installed.\n",
        "    \"\"\"\n",
        "    data = np.asarray(arr)\n",
        "    if np.iscomplexobj(data):\n",
        "        raise ValueError(\"Cannot convert a complex-valued array.\")\n",
        "    shape = list(data.shape)\n",
        "    valid = len(shape) == 2 or ((len(shape) == 3) and\n",
        "                                ((3 in shape) or (4 in shape)))\n",
        "    if not valid:\n",
        "        raise ValueError(\"'arr' does not have a suitable array shape for \"\n",
        "                         \"any mode.\")\n",
        "    if len(shape) == 2:\n",
        "        shape = (shape[1], shape[0])  # columns show up first\n",
        "        if mode == 'F':\n",
        "            data32 = data.astype(np.float32)\n",
        "            image = Image.frombytes(mode, shape, data32.tostring())\n",
        "            return image\n",
        "        if mode in [None, 'L', 'P']:\n",
        "            bytedata = bytescale(data, high=high, low=low,\n",
        "                                 cmin=cmin, cmax=cmax)\n",
        "            image = Image.frombytes('L', shape, bytedata.tostring())\n",
        "            if pal is not None:\n",
        "                image.putpalette(np.asarray(pal, dtype=np.uint8).tostring())\n",
        "                # Becomes a mode='P' automagically.\n",
        "            elif mode == 'P':  # default gray-scale\n",
        "                pal = (np.arange(0, 256, 1, dtype=np.uint8)[:, np.newaxis] *\n",
        "                       np.ones((3,), dtype=np.uint8)[np.newaxis, :])\n",
        "                image.putpalette(np.asarray(pal, dtype=np.uint8).tostring())\n",
        "            return image\n",
        "        if mode == '1':  # high input gives threshold for 1\n",
        "            bytedata = (data > high)\n",
        "            image = Image.frombytes('1', shape, bytedata.tostring())\n",
        "            return image\n",
        "        if cmin is None:\n",
        "            cmin = np.amin(np.ravel(data))\n",
        "        if cmax is None:\n",
        "            cmax = np.amax(np.ravel(data))\n",
        "        data = (data*1.0 - cmin)*(high - low)/(cmax - cmin) + low\n",
        "        if mode == 'I':\n",
        "            data32 = data.astype(np.uint32)\n",
        "            image = Image.frombytes(mode, shape, data32.tostring())\n",
        "        else:\n",
        "            raise ValueError(_errstr)\n",
        "        return image\n",
        "\n",
        "    # if here then 3-d array with a 3 or a 4 in the shape length.\n",
        "    # Check for 3 in datacube shape --- 'RGB' or 'YCbCr'\n",
        "    if channel_axis is None:\n",
        "        if (3 in shape):\n",
        "            ca = np.flatnonzero(np.asarray(shape) == 3)[0]\n",
        "        else:\n",
        "            ca = np.flatnonzero(np.asarray(shape) == 4)\n",
        "            if len(ca):\n",
        "                ca = ca[0]\n",
        "            else:\n",
        "                raise ValueError(\"Could not find channel dimension.\")\n",
        "    else:\n",
        "        ca = channel_axis\n",
        "\n",
        "    numch = shape[ca]\n",
        "    if numch not in [3, 4]:\n",
        "        raise ValueError(\"Channel axis dimension is not valid.\")\n",
        "\n",
        "    bytedata = bytescale(data, high=high, low=low, cmin=cmin, cmax=cmax)\n",
        "    if ca == 2:\n",
        "        strdata = bytedata.tostring()\n",
        "        shape = (shape[1], shape[0])\n",
        "    elif ca == 1:\n",
        "        strdata = np.transpose(bytedata, (0, 2, 1)).tostring()\n",
        "        shape = (shape[2], shape[0])\n",
        "    elif ca == 0:\n",
        "        strdata = np.transpose(bytedata, (1, 2, 0)).tostring()\n",
        "        shape = (shape[2], shape[1])\n",
        "    if mode is None:\n",
        "        if numch == 3:\n",
        "            mode = 'RGB'\n",
        "        else:\n",
        "            mode = 'RGBA'\n",
        "\n",
        "    if mode not in ['RGB', 'RGBA', 'YCbCr', 'CMYK']:\n",
        "        raise ValueError(_errstr)\n",
        "\n",
        "    if mode in ['RGB', 'YCbCr']:\n",
        "        if numch != 3:\n",
        "            raise ValueError(\"Invalid array shape for mode.\")\n",
        "    if mode in ['RGBA', 'CMYK']:\n",
        "        if numch != 4:\n",
        "            raise ValueError(\"Invalid array shape for mode.\")\n",
        "\n",
        "    # Here we know data and mode is correct\n",
        "    image = Image.frombytes(mode, shape, strdata)\n",
        "    return image\n",
        "\n",
        "def upsample_and_concat(x1, x2, output_channels, in_channels):\n",
        "    pool_size = 2\n",
        "    deconv_filter = tf.Variable(tf.truncated_normal([pool_size, pool_size, output_channels, in_channels], stddev=0.02))\n",
        "    deconv = tf.nn.conv2d_transpose(x1, deconv_filter, tf.shape(x2), strides=[1, pool_size, pool_size, 1])\n",
        "\n",
        "    deconv_output = tf.concat([deconv, x2], 3)\n",
        "    deconv_output.set_shape([None, None, None, output_channels * 2])\n",
        "\n",
        "    return deconv_output\n",
        "\n",
        "\n",
        "def network(input):\n",
        "    conv1 = slim.conv2d(input, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_1')\n",
        "    conv1 = slim.conv2d(conv1, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv1_2')\n",
        "    pool1 = slim.max_pool2d(conv1, [2, 2], padding='SAME')\n",
        "\n",
        "    conv2 = slim.conv2d(pool1, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv2_1')\n",
        "    conv2 = slim.conv2d(conv2, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv2_2')\n",
        "    pool2 = slim.max_pool2d(conv2, [2, 2], padding='SAME')\n",
        "\n",
        "    conv3 = slim.conv2d(pool2, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv3_1')\n",
        "    conv3 = slim.conv2d(conv3, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv3_2')\n",
        "    pool3 = slim.max_pool2d(conv3, [2, 2], padding='SAME')\n",
        "\n",
        "    conv4 = slim.conv2d(pool3, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv4_1')\n",
        "    conv4 = slim.conv2d(conv4, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv4_2')\n",
        "    pool4 = slim.max_pool2d(conv4, [2, 2], padding='SAME')\n",
        "\n",
        "    conv5 = slim.conv2d(pool4, 512, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv5_1')\n",
        "    conv5 = slim.conv2d(conv5, 512, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv5_2')\n",
        "\n",
        "    up6 = upsample_and_concat(conv5, conv4, 256, 512)\n",
        "    conv6 = slim.conv2d(up6, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv6_1')\n",
        "    conv6 = slim.conv2d(conv6, 256, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv6_2')\n",
        "\n",
        "    up7 = upsample_and_concat(conv6, conv3, 128, 256)\n",
        "    conv7 = slim.conv2d(up7, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv7_1')\n",
        "    conv7 = slim.conv2d(conv7, 128, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv7_2')\n",
        "\n",
        "    up8 = upsample_and_concat(conv7, conv2, 64, 128)\n",
        "    conv8 = slim.conv2d(up8, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv8_1')\n",
        "    conv8 = slim.conv2d(conv8, 64, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv8_2')\n",
        "\n",
        "    up9 = upsample_and_concat(conv8, conv1, 32, 64)\n",
        "    conv9 = slim.conv2d(up9, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv9_1')\n",
        "    conv9 = slim.conv2d(conv9, 32, [3, 3], rate=1, activation_fn=lrelu, scope='g_conv9_2')\n",
        "\n",
        "    conv10 = slim.conv2d(conv9, 12, [1, 1], rate=1, activation_fn=None, scope='g_conv10')\n",
        "    out = tf.depth_to_space(conv10, 2)\n",
        "    return out\n",
        "\n",
        "# this function packs the raw image into multiple channels. Arangement depends on the specific camera used\n",
        "def pack_raw(raw):\n",
        "    # pack Bayer image to 4 channels\n",
        "    im = raw.raw_image_visible.astype(np.float32)\n",
        "    black = raw.black_level_per_channel\n",
        "    print(black)\n",
        "    print(raw.raw_pattern)\n",
        "\n",
        "    # normalisation by subtracting the black level and dividing through the bit depth. Change depending on the camera\n",
        "    bit_level = 12 # camera dependent value\n",
        "    im = np.maximum((im - np.mean(black)), 0) / ((2**bit_level -1) - np.mean(black))  \n",
        "  \n",
        "    im = np.expand_dims(im, axis=2)\n",
        "    img_shape = im.shape\n",
        "  \n",
        "    H = img_shape[0]\n",
        "    W = img_shape[1]\n",
        "\n",
        "    # Different cameras have different Bayer filter arrangements. This selects one of the four posibilities automaticaly\n",
        "    if (raw.raw_pattern == ([[1, 0], [2, 3]])).all():\n",
        "      G = im[0:H:2, 0:W:2, :] # Every alternating value starting from position (0,0) \n",
        "      R = im[0:H:2, 1:W:2, :] # Every alternating value starting from position (0,1) \n",
        "      G_e = im[1:H:2, 1:W:2, :] # Every alternating value starting from position (1,1) \n",
        "      B = im[1:H:2, 0:W:2, :] # Every alternating value starting from position (1,0)\n",
        "    if (raw.raw_pattern == ([[0, 1], [3, 2]])).all():\n",
        "      R = im[0:H:2, 0:W:2, :] # Every alternating value starting from position (0,0) \n",
        "      G = im[0:H:2, 1:W:2, :] # Every alternating value starting from position (0,1) \n",
        "      B = im[1:H:2, 1:W:2, :] # Every alternating value starting from position (1,1) \n",
        "      G_e = im[1:H:2, 0:W:2, :] # Every alternating value starting from position (1,0)  \n",
        "    if (raw.raw_pattern == ([[1, 2], [0, 3]])).all():\n",
        "      G = im[0:H:2, 0:W:2, :] # Every alternating value starting from position (0,0) \n",
        "      B = im[0:H:2, 1:W:2, :] # Every alternating value starting from position (0,1) \n",
        "      G_e = im[1:H:2, 1:W:2, :] # Every alternating value starting from position (1,1) \n",
        "      R = im[1:H:2, 0:W:2, :] # Every alternating value starting from position (1,0)\n",
        "    if (raw.raw_pattern == ([[2, 1], [3, 0]])).all():\n",
        "      B = im[0:H:2, 0:W:2, :] # Every alternating value starting from position (0,0) \n",
        "      G = im[0:H:2, 1:W:2, :] # Every alternating value starting from position (0,1) \n",
        "      R = im[1:H:2, 1:W:2, :] # Every alternating value starting from position (1,1) \n",
        "      G_e = im[1:H:2, 0:W:2, :] # Every alternating value starting from position (1,0)\n",
        "    out = np.concatenate((R, G, B, G_e), axis=2) # Always in R-G-B-G format\n",
        "    \n",
        "    return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIet0qLUZNOI",
        "outputId": "91bf0449-94d3-42b8-e8a3-79f5f0ee8452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ]
        }
      ],
      "source": [
        "sess = tf.Session()\n",
        "in_image = tf.placeholder(tf.float32, [None, None, None, 4])\n",
        "gt_image = tf.placeholder(tf.float32, [None, None, None, 3])\n",
        "out_image = network(in_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABWciBIgVWx5",
        "outputId": "3b705c7a-fb8a-4d42-8973-b7d3681a44da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded ./checkpoint/Own_Adam_full/model.ckpt\n",
            "testing\n",
            "10003_00_1s.dng\n",
            "531.544441836341\n",
            "531.4977316061455\n",
            "[528, 528, 528, 528]\n",
            "[[0 1]\n",
            " [3 2]]\n",
            "0.010951663\n",
            "0.010953469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-fde9ddb16a13>:163: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
            "  strdata = bytedata.tostring()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved\n",
            "testing\n",
            "10004_00_1s.dng\n",
            "530.0044680584425\n",
            "529.8875450594976\n",
            "[528, 528, 528, 528]\n",
            "[[0 1]\n",
            " [3 2]]\n",
            "0.009268585\n",
            "0.0091294255\n",
            "saved\n",
            "testing\n",
            "10005_00_1s.dng\n",
            "528.4752284304926\n",
            "528.4849761760414\n",
            "[528, 528, 528, 528]\n",
            "[[0 1]\n",
            " [3 2]]\n",
            "0.0075218854\n",
            "0.0075177625\n",
            "saved\n"
          ]
        }
      ],
      "source": [
        "saver = tf.train.Saver()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
        "if ckpt:\n",
        "    print('loaded ' + ckpt.model_checkpoint_path)\n",
        "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "\n",
        "if not os.path.isdir(result_dir + 'final/'):\n",
        "    os.makedirs(result_dir + 'final/')\n",
        "\n",
        "for test_id in test_ids:\n",
        "    # test the first image in each sequence\n",
        "    print(\"testing\")\n",
        "    # in_files = glob.glob(input_dir + '%05d_00*.ARW' % test_id)\n",
        "    in_files = glob.glob(input_dir + '%05d_00*.dng' % test_id)\n",
        "    for k in range(len(in_files)):\n",
        "        in_path = in_files[k]\n",
        "        in_fn = os.path.basename(in_path)\n",
        "        print(in_fn)\n",
        "        # gt_files = glob.glob(gt_dir + '%05d_00*.ARW' % test_id)\n",
        "        gt_files = glob.glob(gt_dir + '%05d_00*.dng' % test_id)\n",
        "        gt_path = gt_files[0]\n",
        "        gt_fn = os.path.basename(gt_path)\n",
        "        in_exposure = float(in_fn[9:-5])\n",
        "        gt_exposure = float(gt_fn[9:-5])\n",
        "        \n",
        "\n",
        "        raw = rawpy.imread(in_path)\n",
        "        gt_raw = rawpy.imread(gt_path)\n",
        "        in_max = np.mean(raw.raw_image)\n",
        "        gt_max = np.mean(gt_raw.raw_image)\n",
        "        print(in_max)\n",
        "        print(gt_max)\n",
        "\n",
        "        #set the brightness ratio here\n",
        "        ratio = 500 #min(gt_exposure / in_exposure, 300) #min(16*gt_exposure / in_exposure, 800)\n",
        "        input_full = np.expand_dims(pack_raw(raw), axis=0) * ratio\n",
        "\n",
        "        im = raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
        "        # scale_full = np.expand_dims(np.float32(im/65535.0),axis = 0)*ratio\n",
        "        scale_full = np.expand_dims(np.float32(im / 65535.0), axis=0)\n",
        "\n",
        "        \n",
        "        im = gt_raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
        "        gt_full = np.expand_dims(np.float32(im / 65535.0), axis=0)\n",
        "\n",
        "        input_full = np.minimum(input_full, 1.0)\n",
        "\n",
        "        output = sess.run(out_image, feed_dict={in_image: input_full})\n",
        "        output = np.minimum(np.maximum(output, 0), 1)\n",
        "\n",
        "        output = output[0, :, :, :]\n",
        "        gt_full = gt_full[0, :, :, :]\n",
        "        scale_full = scale_full[0, :, :, :]\n",
        "        print(np.mean(scale_full))\n",
        "        print(np.mean(gt_full))\n",
        "        scale_full = scale_full * np.mean(gt_full) / np.mean(\n",
        "            scale_full)  # scale the low-light image to the same mean of the groundtruth\n",
        "        \n",
        "        toimage(output * 255, high=255, low=0, cmin=0, cmax=255).save(\n",
        "            result_dir + 'final/%5d_00_%d_out.png' % (test_id, ratio))\n",
        "        toimage(scale_full * 255, high=255, low=0, cmin=0, cmax=255).save(\n",
        "            result_dir + 'final/%5d_00_%d_scale.png' % (test_id, ratio))\n",
        "        toimage(gt_full * 255, high=255, low=0, cmin=0, cmax=255).save(\n",
        "            result_dir + 'final/%5d_00_%d_gt.png' % (test_id, ratio))\n",
        "        print(\"saved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlOvlyO3F378"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}